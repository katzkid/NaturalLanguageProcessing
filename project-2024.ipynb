{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "05ac3589",
      "metadata": {},
      "source": [
        "## Name: Kartik VISWANATHAN (MSD 2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b4b4977",
      "metadata": {
        "id": "7b4b4977"
      },
      "source": [
        "# Building models for named entity recognition\n",
        "\n",
        "The project consists in building two named entity recognition (NER) systems. The systems will make use of the IOB tagging scheme to detect entities of type PER, ORG, LOC and MISC. The tagging scheme thus includes the following tags, assuming one tag per token:\n",
        "\n",
        "- B-PER and I-PER: token corresponds to the start, resp. the inside, of a person's entity\n",
        "- B-LOC and I-LOC: token corresponds to the start, resp. the inside, of a location entity\n",
        "- B-ORG and I-ORG: token corresponds to the start, resp. the inside, of an organization entity\n",
        "- B-MISC and I-MISC: token corresponds to the start, resp. the inside, of any other named entity\n",
        "- O: token corresponds to no entity\n",
        "\n",
        "## Dataset\n",
        "\n",
        "You are provided with training, validation and test data derived from the CONLL 03 dataset. The dataset has been marginally cleaned and reformatted for facilitated use. You can directly load the three folds from the json file provided:\n",
        "\n",
        "```python\n",
        "with open('conll03-iob-pos.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "```\n",
        "For each fold, the dataset consists of a list of dictionaries, one per sample, with the two fields 'tokens' and 'labels', e.g.\n",
        "\n",
        "{'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'tags': ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']}\n",
        "\n",
        "## TODO\n",
        "\n",
        "Building on the notebooks we've seen during the lectures and on the tipcs below, you task is to build two tagging models:\n",
        "1. a RNN-based model: an embedding layer, a LSTM layer, a feed-forward layer\n",
        "2. a fine-tuned BERT tagger: a BERT (pre-trained) layer, a feed-forward layer\n",
        "The final feed-forward layer procudes a probability distribution over the set possible tags for each input token.\n",
        "\n",
        "For both, we will use BERT's tokenizer, which is a sub-word tokenizer. The advantage of this tokenizer is that the vocabulary is finite (no out-of-vocabulary tokens): you can get the vocabulary size from tokenizer.vocab_size and you don't have to bother with defining your vocabulary and mapping unkown tokens to some special token. The disadvantage of sub-word tokenization is that we will have to relabel the input sequences, which are labeled on a word basis rather than on a sub-word basis. To make things easier, we provide a function that aligns and encode the labels. Note that special tokens will arbitrarily get the tag -100 which is a default value to indicate Torch's loss functions that gradient should not be propagated from there (in other words, ignore thos tokens in training).\n",
        "\n",
        "Another advantage of using the same tokenizer is that you will have to prepare your dataset and the corresponding loaders only once for the two models.\n",
        "\n",
        "Here are the steps you'll have to go through:\n",
        "\n",
        "1. Define a Dataset class that will hold for each sample the list of encoded tokens and the corresponding list of encoded tags. You will then encode the three folds as a Dataset and define the corresponding DataLoader instances.\n",
        "\n",
        "2. Define your LSTM model class and train it. You can get inspired by the RNN language model notebook.\n",
        "\n",
        "3. Define your BERT model class and train it. You can adapt the LLM finetuning notebook, changing the classification head to operate on each token (as for the LSTM) rather than on the embedding of the [CLS] token.\n",
        "\n",
        "4. Evaluate both and compare. Token tag accuracy is one measure (used for instance to measure the convergence of training) but it's not the ultimate one as the final task is not to tag tokens but to detect entities. You should thus also report in the final evaluation the entitu recognition rate.\n",
        "\n",
        "One last thing to think about: comutation of the accuracy for validation and testing must be adapted in two ways compared to what we've seen in the previous notebooks. First, each prediction is a sequence of tags and not a single tag. Second, tags corresponding to the special tokens (indicated as -100 in the reference) must not be accounted for when computing the accuracy.\n",
        "\n",
        "**Good luck no your mission!**\n",
        "\n",
        "## REPORT\n",
        "\n",
        "The report will be a commented notebook. This is not a python programing project but a NLP project. I'm thus expecting you to comment on your model definition choices, to analyze the results and errors, to provide hints at how things could be improved. If you did trial and error cells, please clean up a bit to facilitate reading, leaving only the final version in the report notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eff19c47",
      "metadata": {
        "id": "eff19c47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/katzkid/miniforge3/envs/NLPenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b24dbe85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b24dbe85",
        "outputId": "796fa250-7e23-424c-dafa-de08a0a67d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['O', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-MISC', 'I-MISC']\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# tag to id mapping and vice versa\n",
        "#\n",
        "# for tokens that does not have a tag, we will use -100 as the corresponding tag ID\n",
        "#\n",
        "\n",
        "tag2id = {\n",
        "    'O': 0,\n",
        "    'B-LOC': 1, 'I-LOC': 2,\n",
        "    'B-ORG': 3, 'I-ORG': 4,\n",
        "    'B-PER': 5, 'I-PER': 6,\n",
        "    'B-MISC': 7, 'I-MISC': 8\n",
        "}\n",
        "\n",
        "id2tag = list(tag2id.keys())\n",
        "\n",
        "print(id2tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "33f9ad85",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cu124\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4acd83e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4acd83e2",
        "outputId": "c034edc8-fd28-4788-eb89-774adaad8b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train 14041\n",
            "valid 3250\n",
            "test 3453\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# load data from json file\n",
        "#\n",
        "\n",
        "with open('data.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "for fold in ('train', 'valid', 'test'):\n",
        "    print(fold, len(data[fold]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8MZxxj-0VU5l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MZxxj-0VU5l",
        "outputId": "68ae148d-5493-499c-8966-c073ea07996b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"tokens\": [\n",
            "    \"EU\",\n",
            "    \"rejects\",\n",
            "    \"German\",\n",
            "    \"call\",\n",
            "    \"to\",\n",
            "    \"boycott\",\n",
            "    \"British\",\n",
            "    \"lamb\",\n",
            "    \".\"\n",
            "  ],\n",
            "  \"tags\": [\n",
            "    \"B-ORG\",\n",
            "    \"O\",\n",
            "    \"B-MISC\",\n",
            "    \"O\",\n",
            "    \"O\",\n",
            "    \"O\",\n",
            "    \"B-MISC\",\n",
            "    \"O\",\n",
            "    \"O\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print_json = lambda x: print(json.dumps(x, indent=2))\n",
        "\n",
        "print_json(data['train'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6a9ca5d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408,
          "referenced_widgets": [
            "45d5ff3a87fc40e7b624831b6178b1c7",
            "c7ee7336ff774f86a36ac0c0c331d818",
            "49413d0a1fa147b0a6e15d0cdddb7492",
            "952f07b69f2c44a0ba90f39d1fee335d",
            "8cbcc13a5fd84accb6143ccb209d44bb",
            "c0d727b3a3f146809b163ce0cc9128ea",
            "89a7703a49b8498590a7d4456a89e878",
            "a0b5d71ef1184b15808c477a703c399e",
            "e7bc4833651a41308d5acdac2ed668ee",
            "1cfe90f95bad46afbb83a4393ac1b6b8",
            "7c445e57e42a47d5a1454fcc4f52511e",
            "ed43ba9764f84bb3ae4bab57f1dcf4e1",
            "72928f1befca4666b3fbb2536ccca3d1",
            "d087e51b4c6e4f42910288ada00d3e6c",
            "8f7be2153d8444dfb8fefb80df71f5de",
            "487cc0e16e7649d09e97e0198c4fa245",
            "6f92ebfa3bfd4a408d27a5ff79ba790d",
            "e0a7f10627604ca5a2ffdf9822237622",
            "b254078391fc4dee9bfbe699dcbd2d43",
            "4e6aa3fd11084d0fa25713e60aa6b84d",
            "bc941e94d5c84a8da6a71852b7ddf94f",
            "73e41767c7fe4950a211f51f30d88bab",
            "3c0dd685f1cb43209d08f6ad10584080",
            "e04b9ae018074d8b8f4cb705f6a932e0",
            "0cb3cc78a9eb4238ab6d06d2f1800ef3",
            "5b155e071fcd477c8fdaa0bcbcd01aec",
            "b4b56354f52a435781300e2e71f2a203",
            "1f9b0409abed496d8912bb80c9b8ce11",
            "eb2dabe5073b4cac946886f7dd1aa261",
            "6f7309bae7064b899c01724dfeeb2caa",
            "7cad070baf23490fac4efc9f642ba6a3",
            "0b75f4c6458b499b96e4b9c649c43468",
            "aedcf6fa45ae4b8fb686a5ecf8555db9",
            "7bd0053f0e9f425b888021a22a61b4f1",
            "c29e9a5d9dd04c5682fca0c576ba8282",
            "5cd35186944a4feabfa9767090057e8f",
            "e2cf3e804a9d4c20b162952781e67d13",
            "25065b9e7ce548bda99ef203f3799201",
            "513d1b95a64d4af6b3687ede89266d1d",
            "70603ea985b943a49aad7fea34b9129e",
            "1fc5ac23e27b4ea5bf135a568b737513",
            "1dea8d2f4dd049f4b61a56557962a9ac",
            "8155cf0f0c9b41d9827145164aeed88d",
            "55647f18882d4f2a87ea74854e748ffa"
          ]
        },
        "id": "6a9ca5d2",
        "outputId": "abdd4418-19b8-46bd-fb9d-49caea0ee8c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DistilBertTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# load BERT's tokenizer\n",
        "#\n",
        "\n",
        "checkpoint = 'distilbert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "print(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c486661c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Device: NVIDIA GeForce GTX 1080 Ti\n"
          ]
        }
      ],
      "source": [
        "print(\"GPU Device:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c4878054",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4878054",
        "outputId": "308761c3-3fc9-45c8-b138-35f61bfa0aec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
            "['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Here's an example showing how to tokenize texts and create the corresponding aligned and encoded labels\n",
        "#\n",
        "# Note that the tokenizer enables to retrieve the index of the corresponding word for each (sub-word) token\n",
        "# through the inputs.word_ids(batch_index=i) function (to retrieve input word indices for each token in\n",
        "# inputs['input_ids'][i]). Special tokens ([CLS], [SEP], [PAD]) are mapped to None. We will make use of this\n",
        "# mapping to create token-level labels adapted to sub-word tokenization. See next cell.\n",
        "#\n",
        "\n",
        "train_texts = [x['tokens'] for x in data['train']]\n",
        "train_labels = [x['tags'] for x in data['train']]\n",
        "\n",
        "inputs = tokenizer(train_texts, is_split_into_words=True, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "print(train_texts[0])\n",
        "print(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]))\n",
        "print(inputs.word_ids(batch_index=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "47e0d084",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47e0d084",
        "outputId": "b5cb752f-0fd0-44f6-e4f4-4e946adf93e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Spanish', 'Farm', 'Minister', 'Loyola', 'de', 'Palacio', 'had', 'earlier', 'accused', 'Fischler', 'at', 'an', 'EU', 'farm', 'ministers', \"'\", 'meeting', 'of', 'causing', 'unjustified', 'alarm', 'through', '\"', 'dangerous', 'generalisation', '.', '\"'] ['B-MISC', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "[CLS]  --  NONE\n",
            "Spanish  --  B-MISC\n",
            "Farm  --  O\n",
            "Minister  --  O\n",
            "Loyola  --  B-PER\n",
            "de  --  I-PER\n",
            "Pa  --  I-PER\n",
            "##la  --  I-PER\n",
            "##cio  --  I-PER\n",
            "had  --  O\n",
            "earlier  --  O\n",
            "accused  --  O\n",
            "Fi  --  B-PER\n",
            "##sch  --  I-PER\n",
            "##ler  --  I-PER\n",
            "at  --  O\n",
            "an  --  O\n",
            "EU  --  B-ORG\n",
            "farm  --  O\n",
            "ministers  --  O\n",
            "'  --  O\n",
            "meeting  --  O\n",
            "of  --  O\n",
            "causing  --  O\n",
            "un  --  O\n",
            "##ju  --  O\n",
            "##st  --  O\n",
            "##ified  --  O\n",
            "alarm  --  O\n",
            "through  --  O\n",
            "\"  --  O\n",
            "dangerous  --  O\n",
            "general  --  O\n",
            "##isation  --  O\n",
            ".  --  O\n",
            "\"  --  O\n",
            "[SEP]  --  NONE\n"
          ]
        }
      ],
      "source": [
        "def align_and_encode_labels(_token_ids, _word_ids, _labels):\n",
        "    '''\n",
        "    Align word-level labels to sub-word tokens for an entry\n",
        "    '''\n",
        "\n",
        "    global tag2id\n",
        "\n",
        "    ignore_id = -100\n",
        "\n",
        "    buf = [ignore_id] # ignore tag for token [CLS]\n",
        "\n",
        "    prev_token_word = -1\n",
        "    which_type = 0\n",
        "\n",
        "    # print(len(_token_ids), tokenizer.convert_ids_to_tokens(_token_ids))\n",
        "    # print(_word_ids)\n",
        "    # print(_labels)\n",
        "\n",
        "    for i in range(1, len(_token_ids)):\n",
        "        word_id = _word_ids[i]\n",
        "\n",
        "        if word_id == None:\n",
        "            # token does not belong to any input word ([CLS], [SEP] or [PAD]) -- ignore\n",
        "            buf.append(ignore_id)\n",
        "\n",
        "        else:\n",
        "            tag_id = tag2id[_labels[word_id]]\n",
        "\n",
        "            if word_id == prev_token_word:\n",
        "            # sub-word token of the previous word: need to do something\n",
        "            #   word has an O tag: just use a O tag\n",
        "            #   word has an I-X tag: just use the I-X tag\n",
        "            #   word has a B-X tag: replace by corresponding I-X tag\n",
        "\n",
        "                buf.append(tag_id + 1 if tag_id in (1, 3, 5, 7) else tag_id)\n",
        "\n",
        "            else:\n",
        "                # token starting a new word --> keep tag unchanged\n",
        "                prev_token_word = word_id\n",
        "                buf.append(tag_id)\n",
        "\n",
        "    return buf\n",
        "\n",
        "#\n",
        "# The following illustrate how we can get aligned and encoded labels for sample i in the training set.\n",
        "#\n",
        "\n",
        "i = 10\n",
        "\n",
        "print(train_texts[i], train_labels[i])\n",
        "\n",
        "new_labels = align_and_encode_labels(inputs['input_ids'][i], inputs.word_ids(batch_index=i), train_labels[i])\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][i])\n",
        "\n",
        "for j in range(len(tokens)):\n",
        "    if tokens[j] != '[PAD]':\n",
        "        print(tokens[j], ' -- ', id2tag[new_labels[j]] if new_labels[j] >= 0 else 'NONE')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abb9f6d6",
      "metadata": {},
      "source": [
        "## STEP 1: Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7cad9901",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb64dfd",
      "metadata": {},
      "source": [
        "### Create MyDataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d7c6ea28",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        \n",
        "        assert(len(encodings) == len(labels))\n",
        "        \n",
        "        self.nsamples = len(labels)\n",
        "        \n",
        "        # print(f'Initializing dataset with {self.nsamples} entries')\n",
        "        \n",
        "        self.encodings = encodings # list[list[int]]: contains the padded list of token ids for each sample\n",
        "        self.labels = labels # list[int]: contains the label for each sample\n",
        "        self.nlabels = 9 # number of labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Returns a dictionary containing the label and padded token ids for a sample\n",
        "        '''\n",
        "        \n",
        "        # print(f'accessing dataset item at index {idx}')\n",
        "        # print(torch.tensor(self.encodings[idx]), torch.tensor(self.labels[idx]))\n",
        "\n",
        "        return {'ids': torch.tensor(self.encodings[idx]), 'label': torch.tensor(self.labels[idx])}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fc6a929c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14041 14041\n",
            "[101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
            "3250 3250\n",
            "[101, 15531, 9741, 22441, 1942, 118, 149, 27514, 10954, 9272, 9637, 1708, 3048, 18172, 2036, 157, 1592, 22441, 152, 17145, 2069, 13020, 16972, 2101, 138, 26321, 9637, 15969, 27451, 11780, 1708, 7118, 16647, 9565, 3663, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [-100, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
            "3453 3453\n",
            "[101, 156, 9244, 10954, 2069, 118, 147, 12240, 14962, 25075, 1942, 149, 21986, 2428, 3663, 160, 11607, 117, 24890, 11607, 1592, 15969, 156, 19556, 22861, 6258, 2036, 18581, 2271, 12420, 1942, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [-100, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
            "Training set:  nsamples = 14041  nlabels = 9\n",
            "{'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'tags': ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']}\n",
            "   >> {'ids': tensor([  101,  7270, 22961,  1528,  1840,  1106, 21423,  1418,  2495, 12913,\n",
            "          119,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0]), 'label': tensor([-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100])}\n",
            "{'tokens': ['Peter', 'Blackburn'], 'tags': ['B-PER', 'I-PER']}\n",
            "   >> {'ids': tensor([  101,  1943, 14428,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0]), 'label': tensor([-100,    5,    6, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100])}\n",
            "{'tokens': ['BRUSSELS', '1996-08-22'], 'tags': ['B-LOC', 'O']}\n",
            "   >> {'ids': tensor([  101, 26660, 13329, 12649, 15928,  1820,   118,  4775,   118,  1659,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0]), 'label': tensor([-100,    1,    2,    2,    2,    0,    0,    0,    0,    0, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
            "        -100, -100, -100, -100, -100])}\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Function to convert the dataset as a list[dict] into a proper torch.Dataset object\n",
        "# \n",
        "def to_dataset(texts, labels) -> MyDataset:\n",
        "    '''\n",
        "    Convert data as processed before into a proper pyTorch dataset with the specified tokenizer. \n",
        "    If maxlen <= 0, then we take the maximum length within the sequence.\n",
        "    '''\n",
        "\n",
        "    inputs = tokenizer(texts, is_split_into_words=True, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    encoded_tokens = [inputs['input_ids'][i].tolist() for i in range(len(texts))]\n",
        "    encoded_labels = [align_and_encode_labels(inputs['input_ids'][i].tolist(), inputs.word_ids(batch_index=i), labels[i]) for i in range(len(texts))]\n",
        "\n",
        "    print(len(encoded_tokens), len(encoded_labels))\n",
        "\n",
        "    print(encoded_tokens[0], encoded_labels[0])\n",
        "    \n",
        "    return MyDataset(encoded_tokens, encoded_labels)\n",
        "\n",
        "\n",
        "ds = dict()\n",
        "\n",
        "train_texts = [x['tokens'] for x in data['train']]\n",
        "train_labels = [x['tags'] for x in data['train']]\n",
        "\n",
        "test_texts = [x['tokens'] for x in data['test']]\n",
        "test_labels = [x['tags'] for x in data['test']]\n",
        "\n",
        "val_texts = [x['tokens'] for x in data['valid']]\n",
        "val_labels = [x['tags'] for x in data['valid']]\n",
        "\n",
        "ds['train'] = to_dataset(train_texts, train_labels)\n",
        "ds['valid'] = to_dataset(val_texts, val_labels)\n",
        "ds['test'] = to_dataset(test_texts, test_labels)\n",
        "\n",
        "print('Training set:  nsamples =', ds['train'].nsamples, ' nlabels =', len(tag2id))\n",
        "\n",
        "for i in range(3):\n",
        "    print(data['train'][i])\n",
        "    print('   >>', ds['train'][i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faf03bc7",
      "metadata": {},
      "source": [
        "### Use Dataloader to convert to tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1c31b10e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples: 14041\n",
            "Number of training batches: 878\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Create batched dataset with data loaders\n",
        "#\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "loader = dict()\n",
        "loader['train'] = DataLoader(ds['train'], batch_size=batch_size, shuffle=True) # set to False for debugging purposes\n",
        "loader['valid'] = DataLoader(ds['valid'], batch_size=batch_size)\n",
        "loader['test'] = DataLoader(ds['test'], batch_size=batch_size)\n",
        "\n",
        "print('Number of samples:', len(ds['train']))\n",
        "print(f'Number of training batches:', len(loader['train']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17f6c955",
      "metadata": {},
      "source": [
        "## STEP 2: Create the Recurrent NN model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bf7288e",
      "metadata": {},
      "source": [
        "RNNs: Recurrent Neural Networks process sequences of data by maintaining a hidden state that captures information from previous time steps. They are particularly suited for tasks where the order of data matters, such as time series prediction or language modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "dc1d6d3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "class NERNN(torch.nn.Module):\n",
        "    def __init__(self, vocsize, nclasses=9, embed_dim=200, hidden_dim=200, dropout=0.3):\n",
        "        super(NERNN, self).__init__()\n",
        "        \n",
        "        self.embedding = torch.nn.Embedding(vocsize, embed_dim, padding_idx=0)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.lstm = torch.nn.LSTM(embed_dim, hidden_dim // 2, bidirectional=True, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(hidden_dim, nclasses)\n",
        "        self.nclasses = nclasses\n",
        "        \n",
        "   \n",
        "    def forward(self, ids):\n",
        "        x = self.embedding(ids)  # batch_size * maxlen * embed_dim\n",
        "        if self.dropout is not None:\n",
        "            x = self.dropout(x)\n",
        "        \n",
        "        output, _ = self.lstm(x)  # batch_size * maxlen * hidden_dim\n",
        "        logits = self.linear(output)  # batch_size * maxlen * num_classes\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5f7daa1d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 28996\n",
            "Number of classes: 9\n"
          ]
        }
      ],
      "source": [
        "vocab_size = tokenizer.vocab_size\n",
        "\n",
        "num_classes = len(tag2id)\n",
        "\n",
        "print('Vocabulary size:', vocab_size)\n",
        "print('Number of classes:', ds['train'].nlabels)\n",
        "\n",
        "model = NERNN(vocab_size, nclasses = 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "75b4959a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NERNN(\n",
            "  (embedding): Embedding(28996, 200, padding_idx=0)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (lstm): LSTM(200, 100, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=200, out_features=9, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c3ad430",
      "metadata": {},
      "source": [
        "### Training and evaluation steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ee8fdc39",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_step(_model, _loader, _loss, _optim, device=\"cpu\", report=0):\n",
        "    _model.train(True)\n",
        "    total_loss = 0.\n",
        "    running_loss = 0.\n",
        "\n",
        "    for i, batch in enumerate(_loader):\n",
        "        _optim.zero_grad()\n",
        "\n",
        "        labels = batch['label'].to(device)\n",
        "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'label'}\n",
        "        outputs = _model(**inputs)\n",
        "\n",
        "        # Reshape outputs and labels\n",
        "        outputs = outputs.view(-1, outputs.shape[-1])  # (batch_size * seq_length, num_classes)\n",
        "        labels = labels.view(-1)  # (batch_size * seq_length)\n",
        "\n",
        "        # Ignore padding tokens (label -100)\n",
        "        mask = (labels != -100)\n",
        "        outputs = outputs[mask]\n",
        "        labels = labels[mask]\n",
        "\n",
        "        loss = _loss(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        _optim.step()\n",
        "\n",
        "        if report != 0 and i % report == report - 1:\n",
        "            print('  batch {} avg. loss per batch={:.4f}'.format(i + 1, running_loss / report))\n",
        "            running_loss = 0.\n",
        "\n",
        "    _model.train(False)\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ffed8156",
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_step(_model, _loader, device='cpu', loss_fn=None):\n",
        "    '''\n",
        "    Evaluate the model's performance on data within loader.\n",
        "    \n",
        "    :return: \n",
        "    total_loss accumulated throughout the batches\n",
        "    accuracy\n",
        "    '''\n",
        "    _model.eval()  # disable training mode\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in _loader:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'label'}\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = _model(**inputs)\n",
        "            \n",
        "            if loss_fn is not None:\n",
        "                loss = loss_fn(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            predictions = torch.argmax(outputs, dim=-1)\n",
        "            \n",
        "            # Remove padding tokens\n",
        "            mask = labels != -100\n",
        "            predictions = predictions[mask]\n",
        "            labels = labels[mask]\n",
        "            \n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    return total_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04232336",
      "metadata": {},
      "source": [
        "### Choose the device to run the training and adjust training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "97606c11",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on cuda device\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Last but not least, we have to set the training parameters and instatiate all the objects \n",
        "# needed for training.\n",
        "#\n",
        "\n",
        "lr = 1e-4\n",
        "nepochs = 10\n",
        "report_freq = 100\n",
        "\n",
        "# check what device we can work on\n",
        "if torch.backends.mps.is_built(): # MPS GPU library for MacOS -- requires metal to be installed\n",
        "    device = \"mps\"\n",
        "    torch.mps.empty_cache()\n",
        "elif torch.cuda.is_available(): # CUDA GPU acceleration available\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "print(f'Running on {device} device')\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "celoss = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b28e4d3",
      "metadata": {},
      "source": [
        "### Run the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "284500cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "  batch 100 avg. loss per batch=1.9848\n",
            "  batch 200 avg. loss per batch=1.1641\n",
            "  batch 300 avg. loss per batch=0.9487\n",
            "  batch 400 avg. loss per batch=0.9240\n",
            "  batch 500 avg. loss per batch=0.9189\n",
            "  batch 600 avg. loss per batch=0.8918\n",
            "  batch 700 avg. loss per batch=0.8576\n",
            "  batch 800 avg. loss per batch=0.8407\n",
            "  **train** avg_loss=1.0473    acuracy=76.46%\n",
            "  **valid** avg_loss=0.8830    acuracy=76.43%\n",
            "epoch: 1\n",
            "  batch 100 avg. loss per batch=0.8190\n",
            "  batch 200 avg. loss per batch=0.7708\n",
            "  batch 300 avg. loss per batch=0.7902\n",
            "  batch 400 avg. loss per batch=0.7670\n",
            "  batch 500 avg. loss per batch=0.7595\n",
            "  batch 600 avg. loss per batch=0.7334\n",
            "  batch 700 avg. loss per batch=0.7293\n",
            "  batch 800 avg. loss per batch=0.7062\n",
            "  **train** avg_loss=0.7531    acuracy=81.13%\n",
            "  **valid** avg_loss=0.6880    acuracy=80.86%\n",
            "epoch: 2\n",
            "  batch 100 avg. loss per batch=0.6499\n",
            "  batch 200 avg. loss per batch=0.6386\n",
            "  batch 300 avg. loss per batch=0.6445\n",
            "  batch 400 avg. loss per batch=0.6158\n",
            "  batch 500 avg. loss per batch=0.6260\n",
            "  batch 600 avg. loss per batch=0.5986\n",
            "  batch 700 avg. loss per batch=0.5813\n",
            "  batch 800 avg. loss per batch=0.5739\n",
            "  **train** avg_loss=0.6112    acuracy=84.30%\n",
            "  **valid** avg_loss=0.5663    acuracy=83.71%\n",
            "epoch: 3\n",
            "  batch 100 avg. loss per batch=0.5650\n",
            "  batch 200 avg. loss per batch=0.5249\n",
            "  batch 300 avg. loss per batch=0.5444\n",
            "  batch 400 avg. loss per batch=0.5310\n",
            "  batch 500 avg. loss per batch=0.5286\n",
            "  batch 600 avg. loss per batch=0.4916\n",
            "  batch 700 avg. loss per batch=0.5007\n",
            "  batch 800 avg. loss per batch=0.5148\n",
            "  **train** avg_loss=0.5214    acuracy=86.30%\n",
            "  **valid** avg_loss=0.4918    acuracy=85.38%\n",
            "epoch: 4\n",
            "  batch 100 avg. loss per batch=0.4875\n",
            "  batch 200 avg. loss per batch=0.4730\n",
            "  batch 300 avg. loss per batch=0.4695\n",
            "  batch 400 avg. loss per batch=0.4542\n",
            "  batch 500 avg. loss per batch=0.4607\n",
            "  batch 600 avg. loss per batch=0.4517\n",
            "  batch 700 avg. loss per batch=0.4469\n",
            "  batch 800 avg. loss per batch=0.4476\n",
            "  **train** avg_loss=0.4591    acuracy=87.86%\n",
            "  **valid** avg_loss=0.4397    acuracy=86.64%\n",
            "epoch: 5\n",
            "  batch 100 avg. loss per batch=0.4152\n",
            "  batch 200 avg. loss per batch=0.4376\n",
            "  batch 300 avg. loss per batch=0.4223\n",
            "  batch 400 avg. loss per batch=0.4203\n",
            "  batch 500 avg. loss per batch=0.4159\n",
            "  batch 600 avg. loss per batch=0.4103\n",
            "  batch 700 avg. loss per batch=0.4024\n",
            "  batch 800 avg. loss per batch=0.3882\n",
            "  **train** avg_loss=0.4118    acuracy=89.38%\n",
            "  **valid** avg_loss=0.3911    acuracy=87.93%\n",
            "epoch: 6\n",
            "  batch 100 avg. loss per batch=0.3854\n",
            "  batch 200 avg. loss per batch=0.3771\n",
            "  batch 300 avg. loss per batch=0.3973\n",
            "  batch 400 avg. loss per batch=0.3860\n",
            "  batch 500 avg. loss per batch=0.3862\n",
            "  batch 600 avg. loss per batch=0.3591\n",
            "  batch 700 avg. loss per batch=0.3593\n",
            "  batch 800 avg. loss per batch=0.3658\n",
            "  **train** avg_loss=0.3776    acuracy=90.06%\n",
            "  **valid** avg_loss=0.3765    acuracy=88.33%\n",
            "epoch: 7\n",
            "  batch 100 avg. loss per batch=0.3499\n",
            "  batch 200 avg. loss per batch=0.3584\n",
            "  batch 300 avg. loss per batch=0.3575\n",
            "  batch 400 avg. loss per batch=0.3443\n",
            "  batch 500 avg. loss per batch=0.3504\n",
            "  batch 600 avg. loss per batch=0.3380\n",
            "  batch 700 avg. loss per batch=0.3491\n",
            "  batch 800 avg. loss per batch=0.3351\n",
            "  **train** avg_loss=0.3470    acuracy=90.89%\n",
            "  **valid** avg_loss=0.3530    acuracy=89.16%\n",
            "epoch: 8\n",
            "  batch 100 avg. loss per batch=0.3117\n",
            "  batch 200 avg. loss per batch=0.3382\n",
            "  batch 300 avg. loss per batch=0.3297\n",
            "  batch 400 avg. loss per batch=0.3119\n",
            "  batch 500 avg. loss per batch=0.3277\n",
            "  batch 600 avg. loss per batch=0.3163\n",
            "  batch 700 avg. loss per batch=0.3249\n",
            "  batch 800 avg. loss per batch=0.3092\n",
            "  **train** avg_loss=0.3224    acuracy=91.79%\n",
            "  **valid** avg_loss=0.3300    acuracy=89.86%\n",
            "epoch: 9\n",
            "  batch 100 avg. loss per batch=0.2941\n",
            "  batch 200 avg. loss per batch=0.3044\n",
            "  batch 300 avg. loss per batch=0.3152\n",
            "  batch 400 avg. loss per batch=0.2905\n",
            "  batch 500 avg. loss per batch=0.2936\n",
            "  batch 600 avg. loss per batch=0.2973\n",
            "  batch 700 avg. loss per batch=0.3053\n",
            "  batch 800 avg. loss per batch=0.2972\n",
            "  **train** avg_loss=0.2996    acuracy=92.30%\n",
            "  **valid** avg_loss=0.3170    acuracy=90.37%\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# At last, here we go with the main training loop, iterating over epochs\n",
        "#\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(nepochs):\n",
        "    print(f'epoch: {epoch}')\n",
        "    \n",
        "    total_loss = train_step(model, loader['train'], celoss, optimizer, device=device, report=report_freq)\n",
        "    _, trn_acc = eval_step(model, loader['train'], device=device, loss_fn=None)\n",
        "    \n",
        "    val_loss, val_acc = eval_step(model, loader['valid'], device=device, loss_fn=celoss)\n",
        "\n",
        "    print('  **train** avg_loss={:.4f}    acuracy={:.2f}%'.format(total_loss / len(loader['train']), 100 * trn_acc))\n",
        "    print('  **valid** avg_loss={:.4f}    acuracy={:.2f}%'.format(val_loss / len(loader['valid']), 100 * val_acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8298e791",
      "metadata": {},
      "source": [
        "### Test Accuracy with Recurrent NN for NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "157deb35",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  **test** acuracy=89.03%\n"
          ]
        }
      ],
      "source": [
        "_, tst_acc = eval_step(model, loader['test'], device=device, loss_fn=None)\n",
        "\n",
        "print('  **test** acuracy={:.2f}%'.format(100 * tst_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5526e93",
      "metadata": {},
      "source": [
        "### Short conclusion about RNN\n",
        "* RNNs typically require training on labeled sequences and can be sensitive to the order of input. They often need careful tuning of hyperparameters and may require more epochs to converge. \n",
        "* RNNs require training on labeled sequences and can be sensitive to the order of input. They often need careful tuning of hyperparameters and may require more epochs to converge.\n",
        "* While RNNs can perform well on sequence labeling tasks, their performance may degrade with longer sequences or complex dependencies. They often require more engineering efforts for feature extraction and may not generalize as well.\n",
        "* Less resource intensive. The training went through relatively fast"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7bdf503",
      "metadata": {},
      "source": [
        "## STEP 3: Create model for BERT based NER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bdfd975",
      "metadata": {},
      "source": [
        "BERT: Bidirectional Encoder Representations from Transformers (BERT) is based on the transformer architecture, which uses self-attention mechanisms to process input data. BERT captures context from both directions (left and right) simultaneously, allowing it to understand the meaning of words in relation to their surrounding words."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50c8ccf6",
      "metadata": {},
      "source": [
        "### Get a pre-trained model from Hugging-face\n",
        "While using BERT may involve more complex initial setup due to its architecture and tokenization requirements, pre-trained models are readily available through libraries like Hugging Face's Transformers, making it easier to implement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5c522411",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-26 22:39:44.822001: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-26 22:39:44.822094: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-26 22:39:44.822152: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-26 22:39:44.837630: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-26 22:39:46.000326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DistilBertModel(\n",
              "  (embeddings): Embeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (transformer): Transformer(\n",
              "    (layer): ModuleList(\n",
              "      (0-5): 6 x TransformerBlock(\n",
              "        (attention): DistilBertSdpaAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (ffn): FFN(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (activation): GELUActivation()\n",
              "        )\n",
              "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#\n",
        "# Load tokenizer and model\n",
        "#\n",
        "\n",
        "checkpoint = 'distilbert-base-uncased' # distilroberta-base\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint) # load tokenizer\n",
        "bert = AutoModel.from_pretrained(checkpoint) # load model\n",
        "bert.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ce0f53e",
      "metadata": {},
      "source": [
        "### Our BERT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b662cb41",
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "#\n",
        "# Define the model to do the following:\n",
        "#    1. encode input with the BERT encoder\n",
        "#    2. get embedding of token [CLS] (dimension is 768, i.e.,  encoder.config.dim)\n",
        "#    3. run classification from the [CLS] embedding through two feed-forward layers\n",
        "#\n",
        "\n",
        "class BERTClassifier(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, _encoder, nclasses = 2, dropout = None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "\n",
        "        self.nclasses = nclasses\n",
        "        self.encoder = copy.deepcopy(_encoder) # to avoid modifying the encoder directly\n",
        "        self.dropout = torch.nn.Dropout(dropout) if dropout != None else None\n",
        "        self.linear1 = torch.nn.Linear(self.encoder.config.dim, 100)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(100, nclasses)\n",
        "        # self.softmax = torch.nn.Softmax()\n",
        "\n",
        "    def forward(self, ids):\n",
        "        x = self.encoder(ids)        # run batch through the BERT encoder\n",
        "        x = x.last_hidden_state[:,:,:]    # get embedding of all tokens for each input in the batch\n",
        "        if self.dropout != None:\n",
        "            x = self.dropout(x)\n",
        "        x = self.linear1(x)               # project to a 100-d hidden layer\n",
        "        x = self.activation(x)\n",
        "        if self.dropout != None:\n",
        "            x = self.dropout(x)\n",
        "        x = self.linear2(x)               # project to logits, one per class\n",
        "        # x = self.softmax(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model1 = BERTClassifier(bert, nclasses = 9, dropout = 0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c05e64fa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on cuda device\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Set training parameters\n",
        "#\n",
        "\n",
        "lr = 1e-5\n",
        "nepochs = 10\n",
        "report_freq = 100\n",
        "\n",
        "if torch.backends.mps.is_built(): # MPS GPU library for MacOS -- requires metal to be installed\n",
        "    device = \"mps\"\n",
        "    torch.mps.empty_cache()\n",
        "elif torch.cuda.is_available(): # CUDA GPU acceleration available\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "print(f'Running on {device} device')\n",
        "\n",
        "optimizer = torch.optim.AdamW(model1.parameters(), lr=lr)\n",
        "celoss = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0054c24",
      "metadata": {},
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0b3b6fc5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "  batch 100 avg. loss per batch=1.1476\n",
            "  batch 200 avg. loss per batch=0.9372\n",
            "  batch 300 avg. loss per batch=0.8671\n",
            "  batch 400 avg. loss per batch=0.7961\n",
            "  batch 500 avg. loss per batch=0.7691\n",
            "  batch 600 avg. loss per batch=0.7517\n",
            "  batch 700 avg. loss per batch=0.7125\n",
            "  batch 800 avg. loss per batch=0.6989\n",
            "  **train** avg_loss=0.8206    acuracy=82.23%\n",
            "  **valid** avg_loss=0.6487    acuracy=81.34%\n",
            "epoch: 1\n",
            "  batch 100 avg. loss per batch=0.6075\n",
            "  batch 200 avg. loss per batch=0.5739\n",
            "  batch 300 avg. loss per batch=0.5694\n",
            "  batch 400 avg. loss per batch=0.5353\n",
            "  batch 500 avg. loss per batch=0.5271\n",
            "  batch 600 avg. loss per batch=0.5153\n",
            "  batch 700 avg. loss per batch=0.4927\n",
            "  batch 800 avg. loss per batch=0.4997\n",
            "  **train** avg_loss=0.5319    acuracy=88.04%\n",
            "  **valid** avg_loss=0.4471    acuracy=86.67%\n",
            "epoch: 2\n",
            "  batch 100 avg. loss per batch=0.4242\n",
            "  batch 200 avg. loss per batch=0.4324\n",
            "  batch 300 avg. loss per batch=0.4027\n",
            "  batch 400 avg. loss per batch=0.3951\n",
            "  batch 500 avg. loss per batch=0.3884\n",
            "  batch 600 avg. loss per batch=0.3816\n",
            "  batch 700 avg. loss per batch=0.3815\n",
            "  batch 800 avg. loss per batch=0.3645\n",
            "  **train** avg_loss=0.3931    acuracy=91.24%\n",
            "  **valid** avg_loss=0.3686    acuracy=88.72%\n",
            "epoch: 3\n",
            "  batch 100 avg. loss per batch=0.3387\n",
            "  batch 200 avg. loss per batch=0.3256\n",
            "  batch 300 avg. loss per batch=0.3038\n",
            "  batch 400 avg. loss per batch=0.2873\n",
            "  batch 500 avg. loss per batch=0.3028\n",
            "  batch 600 avg. loss per batch=0.3152\n",
            "  batch 700 avg. loss per batch=0.2885\n",
            "  batch 800 avg. loss per batch=0.3070\n",
            "  **train** avg_loss=0.3064    acuracy=93.24%\n",
            "  **valid** avg_loss=0.3052    acuracy=90.09%\n",
            "epoch: 4\n",
            "  batch 100 avg. loss per batch=0.2539\n",
            "  batch 200 avg. loss per batch=0.2489\n",
            "  batch 300 avg. loss per batch=0.2493\n",
            "  batch 400 avg. loss per batch=0.2490\n",
            "  batch 500 avg. loss per batch=0.2339\n",
            "  batch 600 avg. loss per batch=0.2478\n",
            "  batch 700 avg. loss per batch=0.2329\n",
            "  batch 800 avg. loss per batch=0.2251\n",
            "  **train** avg_loss=0.2416    acuracy=95.26%\n",
            "  **valid** avg_loss=0.2717    acuracy=91.30%\n",
            "epoch: 5\n",
            "  batch 100 avg. loss per batch=0.2101\n",
            "  batch 200 avg. loss per batch=0.2040\n",
            "  batch 300 avg. loss per batch=0.1938\n",
            "  batch 400 avg. loss per batch=0.1923\n",
            "  batch 500 avg. loss per batch=0.1858\n",
            "  batch 600 avg. loss per batch=0.1873\n",
            "  batch 700 avg. loss per batch=0.1968\n",
            "  batch 800 avg. loss per batch=0.1940\n",
            "  **train** avg_loss=0.1951    acuracy=96.59%\n",
            "  **valid** avg_loss=0.2507    acuracy=92.27%\n",
            "epoch: 6\n",
            "  batch 100 avg. loss per batch=0.1655\n",
            "  batch 200 avg. loss per batch=0.1780\n",
            "  batch 300 avg. loss per batch=0.1587\n",
            "  batch 400 avg. loss per batch=0.1647\n",
            "  batch 500 avg. loss per batch=0.1551\n",
            "  batch 600 avg. loss per batch=0.1541\n",
            "  batch 700 avg. loss per batch=0.1500\n",
            "  batch 800 avg. loss per batch=0.1658\n",
            "  **train** avg_loss=0.1605    acuracy=97.41%\n",
            "  **valid** avg_loss=0.2321    acuracy=92.96%\n",
            "epoch: 7\n",
            "  batch 100 avg. loss per batch=0.1292\n",
            "  batch 200 avg. loss per batch=0.1487\n",
            "  batch 300 avg. loss per batch=0.1227\n",
            "  batch 400 avg. loss per batch=0.1348\n",
            "  batch 500 avg. loss per batch=0.1374\n",
            "  batch 600 avg. loss per batch=0.1301\n",
            "  batch 700 avg. loss per batch=0.1257\n",
            "  batch 800 avg. loss per batch=0.1090\n",
            "  **train** avg_loss=0.1311    acuracy=97.46%\n",
            "  **valid** avg_loss=0.2436    acuracy=92.25%\n",
            "epoch: 8\n",
            "  batch 100 avg. loss per batch=0.1149\n",
            "  batch 200 avg. loss per batch=0.1040\n",
            "  batch 300 avg. loss per batch=0.1082\n",
            "  batch 400 avg. loss per batch=0.1067\n",
            "  batch 500 avg. loss per batch=0.1183\n",
            "  batch 600 avg. loss per batch=0.1109\n",
            "  batch 700 avg. loss per batch=0.1008\n",
            "  batch 800 avg. loss per batch=0.1134\n",
            "  **train** avg_loss=0.1082    acuracy=98.55%\n",
            "  **valid** avg_loss=0.2202    acuracy=93.74%\n",
            "epoch: 9\n",
            "  batch 100 avg. loss per batch=0.0831\n",
            "  batch 200 avg. loss per batch=0.0904\n",
            "  batch 300 avg. loss per batch=0.0937\n",
            "  batch 400 avg. loss per batch=0.0811\n",
            "  batch 500 avg. loss per batch=0.0857\n",
            "  batch 600 avg. loss per batch=0.0933\n",
            "  batch 700 avg. loss per batch=0.0877\n",
            "  batch 800 avg. loss per batch=0.0858\n",
            "  **train** avg_loss=0.0868    acuracy=98.94%\n",
            "  **valid** avg_loss=0.2167    acuracy=93.78%\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Run the training loop\n",
        "#\n",
        "model1.to(device)\n",
        "\n",
        "for epoch in range(nepochs):\n",
        "    print(f'epoch: {epoch}')\n",
        "    \n",
        "    total_loss = train_step(model1, loader['train'], celoss, optimizer, device=device, report=report_freq)\n",
        "    _, trn_acc = eval_step(model1, loader['train'], device=device, loss_fn=None)\n",
        "    \n",
        "    val_loss, val_acc = eval_step(model1, loader['valid'], device=device, loss_fn=celoss)\n",
        "\n",
        "    print('  **train** avg_loss={:.4f}    acuracy={:.2f}%'.format(total_loss / len(loader['train']), 100 * trn_acc))\n",
        "    print('  **valid** avg_loss={:.4f}    acuracy={:.2f}%'.format(val_loss / len(loader['valid']), 100 * val_acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c222ee55",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  **test** acuracy=91.10%\n"
          ]
        }
      ],
      "source": [
        "_, tst_acc = eval_step(model1, loader['test'], device=device, loss_fn=None)\n",
        "\n",
        "print('  **test** acuracy={:.2f}%'.format(100 * tst_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2081108d",
      "metadata": {},
      "source": [
        "### Short conclusion about BERT based NER\n",
        "* BERT excels at understanding context due to its self-attention mechanism, which allows it to weigh the importance of all words in a sentence when encoding a particular word. This leads to richer representations that are contextually aware.\n",
        "* Pre-trained on large corpora using unsupervised learning techniques (masked language modeling and next sentence prediction), BERT can be fine-tuned on specific tasks like NER with relatively fewer labeled examples, often leading to better performance.\n",
        "* Generally achieves state-of-the-art results in various NLP tasks, including NER. Its ability to leverage pre-trained knowledge allows it to perform exceptionally well even with limited task-specific data.\n",
        "* Requires substantial computational resources due to its large number of parameters and the complexity of the transformer architecture. Fine-tuning BERT models typically necessitates GPUs or TPUs for efficient training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9389c9ac",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "* Overall the BERT based NER model outperforms the RNN based NER model for the same number of epochs of training.\n",
        "* The BERT based training is considerable slower and computationally taxing than RNN based model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NLPenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b75f4c6458b499b96e4b9c649c43468": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cb3cc78a9eb4238ab6d06d2f1800ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f7309bae7064b899c01724dfeeb2caa",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7cad070baf23490fac4efc9f642ba6a3",
            "value": 213450
          }
        },
        "1cfe90f95bad46afbb83a4393ac1b6b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dea8d2f4dd049f4b61a56557962a9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f9b0409abed496d8912bb80c9b8ce11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc5ac23e27b4ea5bf135a568b737513": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25065b9e7ce548bda99ef203f3799201": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c0dd685f1cb43209d08f6ad10584080": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e04b9ae018074d8b8f4cb705f6a932e0",
              "IPY_MODEL_0cb3cc78a9eb4238ab6d06d2f1800ef3",
              "IPY_MODEL_5b155e071fcd477c8fdaa0bcbcd01aec"
            ],
            "layout": "IPY_MODEL_b4b56354f52a435781300e2e71f2a203"
          }
        },
        "45d5ff3a87fc40e7b624831b6178b1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7ee7336ff774f86a36ac0c0c331d818",
              "IPY_MODEL_49413d0a1fa147b0a6e15d0cdddb7492",
              "IPY_MODEL_952f07b69f2c44a0ba90f39d1fee335d"
            ],
            "layout": "IPY_MODEL_8cbcc13a5fd84accb6143ccb209d44bb"
          }
        },
        "487cc0e16e7649d09e97e0198c4fa245": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49413d0a1fa147b0a6e15d0cdddb7492": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0b5d71ef1184b15808c477a703c399e",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7bc4833651a41308d5acdac2ed668ee",
            "value": 49
          }
        },
        "4e6aa3fd11084d0fa25713e60aa6b84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "513d1b95a64d4af6b3687ede89266d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55647f18882d4f2a87ea74854e748ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b155e071fcd477c8fdaa0bcbcd01aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b75f4c6458b499b96e4b9c649c43468",
            "placeholder": "​",
            "style": "IPY_MODEL_aedcf6fa45ae4b8fb686a5ecf8555db9",
            "value": " 213k/213k [00:00&lt;00:00, 4.66MB/s]"
          }
        },
        "5cd35186944a4feabfa9767090057e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fc5ac23e27b4ea5bf135a568b737513",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dea8d2f4dd049f4b61a56557962a9ac",
            "value": 435797
          }
        },
        "6f7309bae7064b899c01724dfeeb2caa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f92ebfa3bfd4a408d27a5ff79ba790d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70603ea985b943a49aad7fea34b9129e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72928f1befca4666b3fbb2536ccca3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f92ebfa3bfd4a408d27a5ff79ba790d",
            "placeholder": "​",
            "style": "IPY_MODEL_e0a7f10627604ca5a2ffdf9822237622",
            "value": "config.json: 100%"
          }
        },
        "73e41767c7fe4950a211f51f30d88bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bd0053f0e9f425b888021a22a61b4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c29e9a5d9dd04c5682fca0c576ba8282",
              "IPY_MODEL_5cd35186944a4feabfa9767090057e8f",
              "IPY_MODEL_e2cf3e804a9d4c20b162952781e67d13"
            ],
            "layout": "IPY_MODEL_25065b9e7ce548bda99ef203f3799201"
          }
        },
        "7c445e57e42a47d5a1454fcc4f52511e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cad070baf23490fac4efc9f642ba6a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8155cf0f0c9b41d9827145164aeed88d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89a7703a49b8498590a7d4456a89e878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cbcc13a5fd84accb6143ccb209d44bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f7be2153d8444dfb8fefb80df71f5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc941e94d5c84a8da6a71852b7ddf94f",
            "placeholder": "​",
            "style": "IPY_MODEL_73e41767c7fe4950a211f51f30d88bab",
            "value": " 465/465 [00:00&lt;00:00, 18.9kB/s]"
          }
        },
        "952f07b69f2c44a0ba90f39d1fee335d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cfe90f95bad46afbb83a4393ac1b6b8",
            "placeholder": "​",
            "style": "IPY_MODEL_7c445e57e42a47d5a1454fcc4f52511e",
            "value": " 49.0/49.0 [00:00&lt;00:00, 2.01kB/s]"
          }
        },
        "a0b5d71ef1184b15808c477a703c399e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aedcf6fa45ae4b8fb686a5ecf8555db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b254078391fc4dee9bfbe699dcbd2d43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4b56354f52a435781300e2e71f2a203": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc941e94d5c84a8da6a71852b7ddf94f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0d727b3a3f146809b163ce0cc9128ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c29e9a5d9dd04c5682fca0c576ba8282": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_513d1b95a64d4af6b3687ede89266d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_70603ea985b943a49aad7fea34b9129e",
            "value": "tokenizer.json: 100%"
          }
        },
        "c7ee7336ff774f86a36ac0c0c331d818": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0d727b3a3f146809b163ce0cc9128ea",
            "placeholder": "​",
            "style": "IPY_MODEL_89a7703a49b8498590a7d4456a89e878",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d087e51b4c6e4f42910288ada00d3e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b254078391fc4dee9bfbe699dcbd2d43",
            "max": 465,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e6aa3fd11084d0fa25713e60aa6b84d",
            "value": 465
          }
        },
        "e04b9ae018074d8b8f4cb705f6a932e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f9b0409abed496d8912bb80c9b8ce11",
            "placeholder": "​",
            "style": "IPY_MODEL_eb2dabe5073b4cac946886f7dd1aa261",
            "value": "vocab.txt: 100%"
          }
        },
        "e0a7f10627604ca5a2ffdf9822237622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2cf3e804a9d4c20b162952781e67d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8155cf0f0c9b41d9827145164aeed88d",
            "placeholder": "​",
            "style": "IPY_MODEL_55647f18882d4f2a87ea74854e748ffa",
            "value": " 436k/436k [00:00&lt;00:00, 21.1MB/s]"
          }
        },
        "e7bc4833651a41308d5acdac2ed668ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb2dabe5073b4cac946886f7dd1aa261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed43ba9764f84bb3ae4bab57f1dcf4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72928f1befca4666b3fbb2536ccca3d1",
              "IPY_MODEL_d087e51b4c6e4f42910288ada00d3e6c",
              "IPY_MODEL_8f7be2153d8444dfb8fefb80df71f5de"
            ],
            "layout": "IPY_MODEL_487cc0e16e7649d09e97e0198c4fa245"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
